{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b7ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext tensorboard\n",
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03fdc7",
   "metadata": {},
   "source": [
    "## 1. Preprocesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83ed6c0",
   "metadata": {},
   "source": [
    "### 1.1 Preparación del entorno "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf379748",
   "metadata": {},
   "source": [
    "Aquí lo que hago es preaprar los imports principales y las variables de entorno. Ahora están comentadas porque como te dije en el correo estaba teniendo problemas con la versión de Cuda y Keras. Ahora lo he solucionado, pero basicamente lo que pasaba es que estaba usando una versión de Keras (Keras 3) la cual no es compatible con transfomers, al final lo soluciones activando  la variable de entorno TF_USE_LEGACY_KERAS e instalando en mi env de conda tf_keras para tener Keras 2. \n",
    "\n",
    "La variable TF_ENABLE_XLA la desactivé porque se supone que podía ser una causa de un problema de OOM que estaba teniendo durante el entrenamiento, pero al final resultó ser un problema con las versiones de las librerías.\n",
    "\n",
    "La variables de entorno que tienen que ver con CUDA era porque creía que mi entorno virtual de conda (el cual al final lo he tenido que meter en un WLS2 con ubuntu porque en windows estaba teniendo problemas de compatibilidad peores, estaba cogienod) estaba cogiendo la versión de CUDA que no era, porque tenía varias instaladas. Pero era más un fallo de configuración del entorno que eso.\n",
    "\n",
    "También he añadido una sección en la que controlo si el dispositivo con el que se va a entrenar es la GPU, pongo un creciomiento progresivo en el uso de memoria para evitar sobrecarga y también un límite para evitar de nuevo el OOM.\n",
    "\n",
    "La línea tf.config.optimizer.set_jit(False) la usaba cuando tenía desactivado el XLA para evitar así que compilase por XLA y evitar posibles problemas de rendimiento, pero ese no era el problema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c038a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 18:35:24.232024: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-16 18:35:24.417850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750091724.491713   64353 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750091724.514403   64353 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750091724.677110   64353 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750091724.677167   64353 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750091724.677169   64353 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750091724.677170   64353 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-16 18:35:24.696704: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/carlo/miniconda3/envs/tf-gpu-v2/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: 12.5.1\n",
      "cuDNN: 9\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4090 Laptop GPU, compute capability 8.9\n",
      "Mixed precision policy: <Policy \"mixed_float16\">\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/miniconda3/envs/tf-gpu-v2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo: GPU\n",
      "TensorFlow version: 2.19.0\n",
      "Transformers version: 4.52.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "info = tf.sysconfig.get_build_info()\n",
    "print(\"CUDA:\",   info[\"cuda_version\"])\n",
    "print(\"cuDNN:\",  info[\"cudnn_version\"])\n",
    "\n",
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "print(\"Mixed precision policy:\", mixed_precision.global_policy())\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import transformers\n",
    "\n",
    "# Fijamos la semilla para reproducibilidad\n",
    "SEED = 42\n",
    "#random.seed(SEED)\n",
    "#np.random.seed(SEED)\n",
    "#tf.random.set_seed(SEED)\n",
    "tf.keras.utils.set_random_seed(SEED)\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED) \n",
    "tf.config.experimental.enable_op_determinism() # Para evitar problemas de determinismo en TensorFlow \n",
    "\n",
    "# Hiperparámetros\n",
    "NUM_LABELS = 44  # 43 emociones + 1 sin emoción\n",
    "\n",
    "MODEL_NAME = \"beomi/KcELECTRA-base\" #\"beomi/KcELECTRA-base\" \"monologg/kobert\"\n",
    "MAX_LENGTH = 512 # Longitud máxima de las secuencias\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "DROPOUT_RATE   = 0.3      \n",
    "L2_REG         = 1e-5         \n",
    "UNFREEZE_EPOCH = 3        \n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "BASE_LR = 1e-4\n",
    "FT_LR = 2e-5\n",
    "WEIGHT_DECAY   = 0.01    # Decaimiento de pesos \n",
    "BETA_1         = 0.9     # Parámetro β₁ de AdamW\n",
    "BETA_2         = 0.999   # Parámetro β₂ de AdamW\n",
    "EPSILON        = 1e-6    # Epsilon de AdamW para estabilidad numérica\n",
    "\n",
    "# Forzar el uso de la GPU y activamos el crecimiento de memoria y la limitamo para evitar el OOM\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=14336)]\n",
    "    )\n",
    "    device_name = \"GPU\"\n",
    "else:\n",
    "    device_name = \"CPU\"\n",
    "\n",
    "print(\"Dispositivo:\", device_name)\n",
    "    \n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Transformers version:\", transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bcd85a",
   "metadata": {},
   "source": [
    "### 1.2 Previsualización de los datos de entrenamiento, validación y test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37648813",
   "metadata": {},
   "source": [
    "Aquí he cargado los datasets de manera manual, pensé en hacerlo descargando directamente desde huggingface como hacen en el código de KOTE, pero ya que tenía los archivos quise probar a hacerlo así."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b83342d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos cargados de Train: 40000, Val: 5000, Test: 5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39087</td>\n",
       "      <td>내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.</td>\n",
       "      <td>2,13,15,16,29,39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30893</td>\n",
       "      <td>정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...</td>\n",
       "      <td>0,5,7,10,19,22,29,35,36,38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45278</td>\n",
       "      <td>새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...</td>\n",
       "      <td>1,2,7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text  \\\n",
       "0  39087              내가 톰행크스를 좋아하긴 했나보다... 초기 영화 빼고는 다 봤네.   \n",
       "1  30893  정말 상상을 초월하는 무개념 진상들 상대하다 우울증, 공항장애 걸리는 공무원 많아요...   \n",
       "2  45278  새로운 세상과 조우한 자의 어린아이 같은 반응, 어쩌면 회복된 것은 눈이 아닌 순수...   \n",
       "\n",
       "                       labels  \n",
       "0            2,13,15,16,29,39  \n",
       "1  0,5,7,10,19,22,29,35,36,38  \n",
       "2                       1,2,7  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#from datasets import load_dataset\n",
    "\n",
    "# Cargo los datasets en local pero también podría ser desde HuggingFace como en el notebook que da KOTE: dataset = load_dataset(\"searle-j/kote\")\n",
    "\n",
    "train_path = \"train.tsv\"\n",
    "val_path   = \"val.tsv\"    \n",
    "test_path  = \"test.tsv\"\n",
    "\n",
    "columns = [\"id\", \"text\", \"labels\"] \n",
    "df_train = pd.read_csv(train_path, sep=\"\\t\", header=None, names=columns)\n",
    "df_val   = pd.read_csv(val_path,   sep=\"\\t\", header=None, names=columns)\n",
    "df_test  = pd.read_csv(test_path,  sep=\"\\t\", header=None, names=columns)\n",
    "\n",
    "print(f\"Ejemplos cargados de Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")\n",
    "\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d9fe3",
   "metadata": {},
   "source": [
    "#### 1.2.1 Control de sesgos de género"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e781cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Añadidos 3422 ejemplos de género intercambiado. Nuevo tamaño de df_train: 43422\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Definimos el mapeo de términos de género\n",
    "gender_map = {\n",
    "    \"여자\":       \"남자\",      # mujer -> hombre\n",
    "    \"남자\":       \"여자\",      # hombre -> mujer\n",
    "    \"여성\":       \"남성\",      # femenino -> masculino\n",
    "    \"남성\":       \"여성\",      # masculino -> femenino\n",
    "\n",
    "    \"아버지\":     \"어머니\",    # padre -> madre\n",
    "    \"어머니\":     \"아버지\",    # madre -> padre\n",
    "    \"아들\":       \"딸\",        # hijo -> hija\n",
    "    \"딸\":         \"아들\",      # hija -> hijo\n",
    "    \"남편\":       \"아내\",      # esposo -> esposa\n",
    "    \"아내\":       \"남편\",      # esposa -> esposo\n",
    "    \"오빠\":       \"언니\",      # hermano mayor (hablante femenino) -> hermana mayor\n",
    "    \"언니\":       \"오빠\",      # hermana mayor -> hermano mayor (hablante femenino)\n",
    "    \"형\":         \"누나\",      # hermano mayor (hablante masculino) -> hermana mayor\n",
    "    \"누나\":       \"형\",        # hermana mayor -> hermano mayor (hablante masculino)\n",
    "\n",
    "    \"남자친구\":   \"여자친구\",  # novio -> novia\n",
    "    \"여자친구\":   \"남자친구\",  # novia -> novio\n",
    "    \"총각\":       \"처녀\",      # soltero -> soltera\n",
    "    \"처녀\":       \"총각\",      # soltera -> soltero\n",
    "\n",
    "    \"왕자\":       \"공주\",      # príncipe -> princesa\n",
    "    \"공주\":       \"왕자\",      # princesa -> príncipe\n",
    "    \"왕\":         \"여왕\",      # rey -> reina\n",
    "    \"여왕\":       \"왕\",        # reina -> rey\n",
    "\n",
    "    \"남배우\":     \"여배우\",    # actor -> actriz\n",
    "    \"여배우\":     \"남배우\",    # actriz -> actor\n",
    "\n",
    "    \"그는\":       \"그녀는\",    # él (sujeto) -> ella (sujeto)\n",
    "    \"그녀는\":     \"그는\",      # ella (sujeto) -> él (sujeto)\n",
    "    \"그를\":       \"그녀를\",    # lo/le (objeto) -> la/le (objeto)\n",
    "    \"그녀를\":     \"그를\",      # la/le (objeto) -> lo/le (objeto)\n",
    "    \"그의\":       \"그녀의\",    # su (masculino) -> su (femenino)\n",
    "    \"그녀의\":     \"그의\",      # su (femenino) -> su (masculino)\n",
    "\n",
    "    \"남성적\":     \"여성적\",    # masculino (adjetivo) -> femenino (adjetivo)\n",
    "    \"여성적\":     \"남성적\",    # femenino (adjetivo) -> masculino (adjetivo)\n",
    "}\n",
    "\n",
    "\n",
    "# Identificamos las filas cuyos textos contienen alguna clave de gender_map\n",
    "pattern = \"|\".join(map(re.escape, gender_map.keys()))\n",
    "mask = df_train['text'].str.contains(pattern)\n",
    "\n",
    "# Creamos un DataFrame con las filas a gender-swappear\n",
    "df_swapped = df_train[mask].copy()\n",
    "\n",
    "# Aplicamos el reemplazo en la columna de texto\n",
    "def swap_gender_tokens(txt):\n",
    "    for src, tgt in gender_map.items():\n",
    "        txt = txt.replace(src, tgt)\n",
    "    return txt\n",
    "\n",
    "df_swapped['text'] = df_swapped['text'].apply(swap_gender_tokens)\n",
    "\n",
    "# Concatenamos y barajamos el DataFrame resultante antes del split\n",
    "df_train = pd.concat([df_train, df_swapped], ignore_index=True)\n",
    "df_train = df_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(f\"Añadidos {len(df_swapped)} ejemplos de género intercambiado. Nuevo tamaño de df_train: {len(df_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8b35a",
   "metadata": {},
   "source": [
    "### 1.3 Binarización de las etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4c3f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de y_train: (43422, 44)\n",
      "Ejemplo de vector de etiquetas (multi-hot) para una muestra:\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Para convertir la columna labels de string a lista de ints\n",
    "def parse_labels(label_str):\n",
    "    if pd.isna(label_str) or label_str == \"\":\n",
    "        return []\n",
    "    return [int(x) for x in label_str.split(\",\")]\n",
    "\n",
    "train_label_lists = df_train[\"labels\"].apply(parse_labels)\n",
    "val_label_lists   = df_val[\"labels\"].apply(parse_labels)\n",
    "test_label_lists  = df_test[\"labels\"].apply(parse_labels)\n",
    "\n",
    "# Pasamos la lisa de etiquetas a un formato multi-hot\n",
    "# (una lista de listas de etiquetas, donde cada lista tiene el mismo tamaño que el número total de etiquetas)\n",
    "mlb = MultiLabelBinarizer(classes=list(range(NUM_LABELS)))\n",
    "mlb.fit(train_label_lists)\n",
    "\n",
    "y_train = mlb.transform(train_label_lists)\n",
    "y_val   = mlb.transform(val_label_lists)\n",
    "y_test  = mlb.transform(test_label_lists)\n",
    "\n",
    "print(\"Tamaño de y_train:\", y_train.shape)\n",
    "print(\"Ejemplo de vector de etiquetas (multi-hot) para una muestra:\\n\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa790da",
   "metadata": {},
   "source": [
    "### 1.4 Revisión de los comentarios y pasarlos a listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22be64e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto de ejemplo: 밤을 꼬박 샜다..  오늘이 일요일이라 다행이다.\n",
      "Etiquetas de ejemplo: [4, 14, 22, 23, 27, 29, 33, 34, 42, 43]\n",
      "Vector multi-hot: [0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Pasamos los comentarios también a listas\n",
    "train_texts = df_train[\"text\"].tolist()\n",
    "val_texts   = df_val[\"text\"].tolist()\n",
    "test_texts  = df_test[\"text\"].tolist()\n",
    "\n",
    "print(\"Texto de ejemplo:\", train_texts[0])\n",
    "print(\"Etiquetas de ejemplo:\", train_label_lists.iloc[0])\n",
    "print(\"Vector multi-hot:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd2e0c",
   "metadata": {},
   "source": [
    "### 1.5 Definición del tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "359be512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9a374",
   "metadata": {},
   "source": [
    "## 2. Definición del modelo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69031ccc",
   "metadata": {},
   "source": [
    "### 2.1 Carga del modelo preentrenado de transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9adf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750091730.767420   64353 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14336 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'electra.embeddings.position_ids', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing TFElectraModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFElectraModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "transformer_model = TFAutoModel.from_pretrained(MODEL_NAME, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ef877",
   "metadata": {},
   "source": [
    "### 2.2 Pooling de Representaciones y Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c12fc63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model, regularizers\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "\n",
    "def build_model():\n",
    "    # 1) Carga limpia del transformer\n",
    "    config = AutoConfig.from_pretrained(MODEL_NAME)\n",
    "    transformer = TFAutoModel.from_pretrained(MODEL_NAME, config=config)\n",
    "    # 2) Entradas\n",
    "    input_ids     = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = tf.keras.Input(shape=(None,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    # 3) Forward + pooling (aquí usamos mean pooling; puedes cambiar a CLS token si lo prefieres)\n",
    "    outputs = transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    sequence_output = outputs.last_hidden_state\n",
    "    pooled_output = tf.reduce_mean(sequence_output, axis=1)\n",
    "    # 4) Cabeza de clasificación\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\",\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(L2_REG)\n",
    "                             )(pooled_output)\n",
    "    x = tf.keras.layers.Dropout(DROPOUT_RATE)(x)\n",
    "    logits = tf.keras.layers.Dense(NUM_LABELS, activation=\"sigmoid\",\n",
    "                                   kernel_regularizer=tf.keras.regularizers.l2(L2_REG)\n",
    "                                  )(x)\n",
    "    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=logits)\n",
    "\n",
    "    return model, transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0eda8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiamos la sesión de Keras para evitar el OOM\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5bc188",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcfd968",
   "metadata": {},
   "source": [
    "### 3.1 Guardado del modelo y callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a579966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Directorio para guardar el mejor modelo\n",
    "#checkpoint_path = \"best_model.h5\"\n",
    "clean_name = re.sub(r'[^A-Za-z0-9._-]', '_', MODEL_NAME)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "checkpoint_path = f\"{clean_name}_{timestamp}.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1), # Así evitamos el overfitting\n",
    "    ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1), # Nos quedamos con el mejor modelo\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, verbose=1), # Reducimos el learning rate si no mejora la val_loss\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf62ca98",
   "metadata": {},
   "source": [
    "### 3.2 Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c02feec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Función generadora de datos para tf.data.Dataset ──\n",
    "def data_generator(texts, labels):\n",
    "    for text, label in zip(texts, labels):\n",
    "        # Tokeniza sin padding fijo; el padding lo hará el batch\n",
    "        enc = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH,\n",
    "            padding=False\n",
    "        )\n",
    "        input_ids     = enc[\"input_ids\"]\n",
    "        attention_mask = enc[\"attention_mask\"]\n",
    "        yield (input_ids, attention_mask), label\n",
    "\n",
    "# ── Tipos y formas de la salida para from_generator ──\n",
    "output_types = (\n",
    "    (tf.int32, tf.int32),  # (input_ids, attention_mask)\n",
    "    tf.int32              # label multietiqueta\n",
    ")\n",
    "\n",
    "output_shapes = (\n",
    "    (tf.TensorShape([None]), tf.TensorShape([None])),  # secuencia variable\n",
    "    tf.TensorShape([NUM_LABELS])                       # vector de etiquetas\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02eddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'electra.embeddings.position_ids', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing TFElectraModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFElectraModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFElectraModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFElectraModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LossScaleOptimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# — Pre‐entrenamiento de la cabeza —\u001b[39;00m\n\u001b[32m     54\u001b[39m opt1 = AdamW(\n\u001b[32m     55\u001b[39m     learning_rate=BASE_LR,\n\u001b[32m     56\u001b[39m     weight_decay=WEIGHT_DECAY,\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     epsilon=EPSILON\n\u001b[32m     60\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m opt1 = \u001b[43mLossScaleOptimizer\u001b[49m(opt1)\n\u001b[32m     63\u001b[39m transformer_model.trainable = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     64\u001b[39m model.compile(\n\u001b[32m     65\u001b[39m     optimizer=opt1,\n\u001b[32m     66\u001b[39m     loss=\u001b[33m\"\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m     metrics=[AUC(name=\u001b[33m\"\u001b[39m\u001b[33mAUC\u001b[39m\u001b[33m\"\u001b[39m, multi_label=\u001b[38;5;28;01mTrue\u001b[39;00m)]\n\u001b[32m     68\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'LossScaleOptimizer' is not defined"
     ]
    }
   ],
   "source": [
    "# ── 1) Combinar train + val ──\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.optimizers.experimental import AdamW\n",
    "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
    "\n",
    "\n",
    "texts_all  = train_texts + val_texts\n",
    "labels_all = np.vstack([y_train, y_val])  # shape = (len(train)+len(val), NUM_LABELS)\n",
    "\n",
    "# ── 2) Preparar CV ──\n",
    "mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_aucs = []\n",
    "\n",
    "# ── 3) Loop de folds ──\n",
    "for fold, (train_idx, val_idx) in enumerate(mskf.split(texts_all, labels_all), start=1):\n",
    "    print(f\"\\n>>> Fold {fold}\")\n",
    "\n",
    "    # Partición de textos y etiquetas\n",
    "    X_tr = [texts_all[i] for i in train_idx]\n",
    "    y_tr = labels_all[train_idx]\n",
    "    X_va = [texts_all[i] for i in val_idx]\n",
    "    y_va = labels_all[val_idx]\n",
    "\n",
    "    # Construir tf.data.Dataset para este fold\n",
    "    train_ds = (\n",
    "        tf.data.Dataset\n",
    "          .from_generator(lambda: data_generator(X_tr, y_tr),\n",
    "                          output_types=output_types,\n",
    "                          output_shapes=output_shapes)\n",
    "          .shuffle(len(X_tr), seed=42)\n",
    "          .padded_batch(\n",
    "              BATCH_SIZE,\n",
    "              padded_shapes=(([None], [None]), [NUM_LABELS]),\n",
    "              padding_values=((tokenizer.pad_token_id, 0), 0)\n",
    "          )\n",
    "          .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    val_ds = (\n",
    "        tf.data.Dataset\n",
    "          .from_generator(lambda: data_generator(X_va, y_va),\n",
    "                          output_types=output_types,\n",
    "                          output_shapes=output_shapes)\n",
    "          .padded_batch(\n",
    "              BATCH_SIZE,\n",
    "              padded_shapes=(([None], [None]), [NUM_LABELS]),\n",
    "              padding_values=((tokenizer.pad_token_id, 0), 0)\n",
    "          )\n",
    "          .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    # Construir modelo desde cero\n",
    "    model, transformer_model = build_model()\n",
    "\n",
    "    # — Pre‐entrenamiento de la cabeza —\n",
    "    opt1 = AdamW(\n",
    "        learning_rate=BASE_LR,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        beta_1=BETA_1,\n",
    "        beta_2=BETA_2,\n",
    "        epsilon=EPSILON\n",
    "    )\n",
    "    opt1 = LossScaleOptimizer(opt1)\n",
    "\n",
    "    transformer_model.trainable = False\n",
    "    model.compile(\n",
    "        optimizer=opt1,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[AUC(name=\"AUC\", multi_label=True)]\n",
    "    )\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=UNFREEZE_EPOCH-1,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # — Fine-tuning completo —\n",
    "    opt2 = AdamW(\n",
    "        learning_rate=FT_LR,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        beta_1=BETA_1,\n",
    "        beta_2=BETA_2,\n",
    "        epsilon=EPSILON\n",
    "    )\n",
    "    opt2 = LossScaleOptimizer(opt2)\n",
    "\n",
    "    transformer_model.trainable = True\n",
    "    model.compile(\n",
    "        optimizer=opt2,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[AUC(name=\"AUC\", multi_label=True)]\n",
    "    )\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        initial_epoch=UNFREEZE_EPOCH-1,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluación de este fold\n",
    "    m = model.evaluate(val_ds, return_dict=True)\n",
    "    print(f\"Fold {fold} — AUC:\", m[\"AUC\"])\n",
    "    fold_aucs.append(m[\"AUC\"])\n",
    "\n",
    "# ── 4) Resultados finales de CV ──\n",
    "print(\"\\nAUC por fold:\", fold_aucs)\n",
    "print(\"Media ± std:\", np.mean(fold_aucs), \"±\", np.std(fold_aucs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-v2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
